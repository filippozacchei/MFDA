{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'solvers_h1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m     solver_low\u001b[38;5;241m.\u001b[39mrandom_process\u001b[38;5;241m.\u001b[39meigenvectors \u001b[38;5;241m=\u001b[39m solver_high\u001b[38;5;241m.\u001b[39mrandom_process\u001b[38;5;241m.\u001b[39meigenvectors[bool_mask]  \n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Setup random processes between solvers\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m setup_random_process(\u001b[43msolvers_h1\u001b[49m, solvers_h2)\n\u001b[1;32m     82\u001b[0m setup_random_process(solvers_h1, solvers_h3)\n\u001b[1;32m     83\u001b[0m setup_random_process(solvers_h1, solvers_h4)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'solvers_h1' is not defined"
     ]
    }
   ],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# Optimize performance by setting environment variables\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from timeit import repeat\n",
    "\n",
    "# Third-party Library Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import arviz as az\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde, multivariate_normal, uniform\n",
    "from tensorflow.keras.models import load_model\n",
    "from itertools import product\n",
    "from numba import jit\n",
    "\n",
    "# Local Module Imports\n",
    "sys.path.append('./data/data_generation/')\n",
    "import tinyDA as tda\n",
    "\n",
    "from model import Model\n",
    "# from utils import *\n",
    "\n",
    "case = \"1-step\"  # Options: \"2-step\"/\"1-step\"/\"FOM\"\n",
    "\n",
    "# MCMC Parameters\n",
    "noise        = 0.001\n",
    "scaling      = 0.05\n",
    "scaling1     = 1\n",
    "scaling2     = 1\n",
    "scaling3     = 1\n",
    "n_iter       = 600\n",
    "burnin       = 100\n",
    "thin         = 1\n",
    "sub_sampling = [10,5]\n",
    "\n",
    "# Initialize Parameters\n",
    "n_samples = 25\n",
    "np.random.seed(123)\n",
    "random_samples = np.random.randint(0, 160, n_samples)\n",
    "n_eig = 64\n",
    "X_values = np.loadtxt('data/data/X_test_h1_100_01.csv', delimiter=',')\n",
    "y_values = np.loadtxt('data/data/y_test_h1_100_01.csv', delimiter=',')\n",
    "\n",
    "# Resolution Parameters for Different Solvers\n",
    "resolutions = [(100, 100), (50, 50), (25, 25), (10, 10)]\n",
    "field_mean, field_stdev, lamb_cov, mkl = 1, 1, 0.1, 64 \n",
    "\n",
    "    ### Chapter one> how I overcame mz fear of codin\n",
    "\n",
    "# Instantiate Models for Different Resolutions\n",
    "solver_h1 = Model(resolutions[0], field_mean, field_stdev, mkl, lamb_cov)\n",
    "solver_h2 = Model(resolutions[1], field_mean, field_stdev, mkl, lamb_cov)\n",
    "solver_h3 = Model(resolutions[2], field_mean, field_stdev, mkl, lamb_cov)\n",
    "solver_h4 = Model(resolutions[3], field_mean, field_stdev, mkl, lamb_cov)\n",
    "\n",
    "def setup_random_process(solver_high, solver_low):\n",
    "    \"\"\"\n",
    "    Synchronize the random processes between the higher and lower fidelity models\n",
    "    by matching transmissivity fields across different resolutions.\n",
    "    \"\"\"\n",
    "    coords_high = solver_high.solver.mesh.coordinates()\n",
    "    coords_low = solver_low.solver.mesh.coordinates()\n",
    "    \n",
    "    structured_high = np.array(coords_high).view([('', coords_high.dtype)] * coords_high.shape[1])\n",
    "    structured_low = np.array(coords_low).view([('', coords_low.dtype)] * coords_low.shape[1])\n",
    "    \n",
    "    bool_mask = np.in1d(structured_high, structured_low)\n",
    "    solver_low.random_process.eigenvalues = solver_high.random_process.eigenvalues\n",
    "    solver_low.random_process.eigenvectors = solver_high.random_process.eigenvectors[bool_mask]  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup random processes between solvers\n",
    "setup_random_process(solver_h1, solver_h2)\n",
    "setup_random_process(solver_h1, solver_h3)\n",
    "setup_random_process(solver_h1, solver_h4)\n",
    "\n",
    "# Define Points for Data Extraction\n",
    "x_data = y_data = np.array([0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "datapoints = np.array(list(product(x_data, y_data)))\n",
    "\n",
    "# Solver Data Functions\n",
    "def solver_h1_data(x):\n",
    "    solver_h1.solve(x)\n",
    "    return solver_h1.get_data(datapoints)\n",
    "def solver_h2_data(x):\n",
    "    solver_h2.solve(x) \n",
    "    return solver_h2.get_data(datapoints)\n",
    "def solver_h3_data(x): \n",
    "    solver_h3.solve(x)\n",
    "    return solver_h3.get_data(datapoints)\n",
    "def solver_h4_data(x): \n",
    "    solver_h4.solve(x)\n",
    "    return solver_h4.get_data(datapoints)\n",
    "\n",
    "def model_HF(input): return solver_h1_data(input).flatten()\n",
    "def model_LF1(input): return solver_h2_data(input).flatten()\n",
    "def model_LF2(input): return solver_h3_data(input).flatten()\n",
    "def model_LF3(input): return solver_h4_data(input).flatten()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009062300566583871\n",
      "0.0008098156275227666\n",
      "0.0007159502161666751\n",
      "Sample = 109\n",
      "[0.9564479  0.8841571  0.86788327 0.87858546 0.910012   0.8146133\n",
      " 0.76014256 0.7290053  0.6728442  0.6965503  0.43945324 0.4523449\n",
      " 0.4816191  0.56627077 0.5644229  0.22606157 0.23834382 0.28414515\n",
      " 0.29701015 0.43436247 0.0821754  0.07835829 0.04931031 0.05931016\n",
      " 0.07404209]\n",
      "[0.96192542 0.88050663 0.86865022 0.88009208 0.91090491 0.81368249\n",
      " 0.76461159 0.72644523 0.67516483 0.69961803 0.43187063 0.45375642\n",
      " 0.48067429 0.56770859 0.56693449 0.21962048 0.23454837 0.28713743\n",
      " 0.29760478 0.43583237 0.08227923 0.07619704 0.05019349 0.05727882\n",
      " 0.0724779 ]\n",
      "(25,)\n",
      "(25,)\n",
      "\n",
      "MSE coarse simulation 1 test:  3.0811e-03\n",
      "\n",
      "MSE coarse simulation 2 test:  9.4146e-04\n",
      "\n",
      "MSE coarse simulation 3 test:  1.3975e-04\n",
      "\n",
      "MSE coarse simulation HF test:  0.0000e+00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 170\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mls\u001b[39m(x):\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (y_true\u001b[38;5;241m-\u001b[39mmodel_HF(x))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 170\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mleast_squares\u001b[49m\u001b[43m(\u001b[49m\u001b[43mls\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_true\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m3-point\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m covariance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(res\u001b[38;5;241m.\u001b[39mjac\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m res\u001b[38;5;241m.\u001b[39mjac)\n\u001b[1;32m    172\u001b[0m covariance \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(covariance))\n",
      "File \u001b[0;32m~/miniconda3/envs/eccomas/lib/python3.11/site-packages/scipy/optimize/_lsq/least_squares.py:941\u001b[0m, in \u001b[0;36mleast_squares\u001b[0;34m(fun, x0, jac, bounds, method, ftol, xtol, gtol, x_scale, loss, f_scale, diff_step, tr_solver, tr_options, jac_sparsity, max_nfev, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m     result \u001b[38;5;241m=\u001b[39m call_minpack(fun_wrapped, x0, jac_wrapped, ftol, xtol, gtol,\n\u001b[1;32m    938\u001b[0m                           max_nfev, x_scale, diff_step)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 941\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtrf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mftol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mgtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_nfev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_solver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtr_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdogbox\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tr_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlsmr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregularize\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tr_options:\n",
      "File \u001b[0;32m~/miniconda3/envs/eccomas/lib/python3.11/site-packages/scipy/optimize/_lsq/trf.py:119\u001b[0m, in \u001b[0;36mtrf\u001b[0;34m(fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale, loss_function, tr_solver, tr_options, verbose)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrf\u001b[39m(fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale,\n\u001b[1;32m    113\u001b[0m         loss_function, tr_solver, tr_options, verbose):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# For efficiency, it makes sense to run the simplified version of the\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# algorithm when no bounds are imposed. We decided to write the two\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# separate functions. It violates the DRY principle, but the individual\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# functions are kept the most readable.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(lb \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(ub \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39minf):\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrf_no_bounds\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mftol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_nfev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_solver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trf_bounds(\n\u001b[1;32m    124\u001b[0m             fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale,\n\u001b[1;32m    125\u001b[0m             loss_function, tr_solver, tr_options, verbose)\n",
      "File \u001b[0;32m~/miniconda3/envs/eccomas/lib/python3.11/site-packages/scipy/optimize/_lsq/trf.py:536\u001b[0m, in \u001b[0;36mtrf_no_bounds\u001b[0;34m(fun, jac, x0, f0, J0, ftol, xtol, gtol, max_nfev, x_scale, loss_function, tr_solver, tr_options, verbose)\u001b[0m\n\u001b[1;32m    532\u001b[0m f_true \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    534\u001b[0m cost \u001b[38;5;241m=\u001b[39m cost_new\n\u001b[0;32m--> 536\u001b[0m J \u001b[38;5;241m=\u001b[39m \u001b[43mjac\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m njev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/eccomas/lib/python3.11/site-packages/scipy/optimize/_lsq/least_squares.py:898\u001b[0m, in \u001b[0;36mleast_squares.<locals>.jac_wrapped\u001b[0;34m(x, f)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjac_wrapped\u001b[39m(x, f):\n\u001b[0;32m--> 898\u001b[0m     J \u001b[38;5;241m=\u001b[39m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiff_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparsity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac_sparsity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m J\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:  \u001b[38;5;66;03m# J is guaranteed not sparse.\u001b[39;00m\n\u001b[1;32m    902\u001b[0m         J \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d(J)\n",
      "File \u001b[0;32m~/miniconda3/envs/eccomas/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:519\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/eccomas/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:602\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    600\u001b[0m x2 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n\u001b[1;32m    601\u001b[0m dx \u001b[38;5;241m=\u001b[39m x2[i] \u001b[38;5;241m-\u001b[39m x1[i]\n\u001b[0;32m--> 602\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m f2 \u001b[38;5;241m=\u001b[39m fun(x2)\n\u001b[1;32m    604\u001b[0m df \u001b[38;5;241m=\u001b[39m f2 \u001b[38;5;241m-\u001b[39m f1\n",
      "File \u001b[0;32m~/miniconda3/envs/eccomas/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:470\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(x\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    468\u001b[0m     x \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(x, x0\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 470\u001b[0m f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 168\u001b[0m, in \u001b[0;36mls\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mls\u001b[39m(x):\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (y_true\u001b[38;5;241m-\u001b[39m\u001b[43mmodel_HF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "Cell \u001b[0;32mIn[13], line 121\u001b[0m, in \u001b[0;36mmodel_HF\u001b[0;34m(input)\u001b[0m\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodel_HF\u001b[39m(\u001b[38;5;28minput\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msolver_h1_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m, in \u001b[0;36msolver_h1_data\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msolver_h1_data\u001b[39m(x):\n\u001b[0;32m---> 12\u001b[0m     \u001b[43msolver_h1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m solver_h1\u001b[38;5;241m.\u001b[39mget_data(datapoints)\n",
      "File \u001b[0;32m~/MFDA/examples/groundwater_flow/./data/data_generation/model.py:38\u001b[0m, in \u001b[0;36mModel.solve\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_process\u001b[38;5;241m.\u001b[39mparameters\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mset_conductivity(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_process\u001b[38;5;241m.\u001b[39mrandom_field)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MFDA/examples/groundwater_flow/./data/data_generation/GwFlow.py:120\u001b[0m, in \u001b[0;36mGwFlowSolver.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m prm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkrylov_solver\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximum_iterations\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000000\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Solve the variational problem\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "case=\"1-step\"\n",
    "# Model Definitions for Different Cases\n",
    "if case == \"2-step\":\n",
    "    # Load Models for Low- and Multi-fidelity Predictions\n",
    "        # Load Models for Low- and Multi-fidelity Predictions\n",
    "    model_nn = [load_model(f'models/single_fidelity_100/resolution_10/samples_64000/model_fold_{i}.keras') for i in range(1,5)]\n",
    "    models_1 = load_model(f'models/multi_fidelity_100_2step/input_10/samples_64000/model_fold_1.keras')\n",
    "    models_2 = load_model(f'models/multi_fidelity_100_2step/input_10_25/samples_64000/model_fold_1.keras')\n",
    "    models_3 = load_model(f'models/multi_fidelity_100_2step/input_10_25_50/samples_64000/model_fold_1.keras')\n",
    "    \n",
    "    @tf.function(jit_compile=True) \n",
    "    def model_mf1(input1, input2):\n",
    "        input1    = tf.reshape(input1, (1, 64))\n",
    "        input2    = tf.reshape(input2, (1, 25))\n",
    "        return models_1([input1,input2], training=False)[0]\n",
    "    \n",
    "    @tf.function(jit_compile=True) \n",
    "    def model_mf2(input1, input2, input3):\n",
    "        input1    = tf.reshape(input1, (1, 64))\n",
    "        input2    = tf.reshape(input2, (1, 25))\n",
    "        input3    = tf.reshape(input3, (1, 25))\n",
    "        return models_2([input1,input2,input3], training=False)[0]\n",
    "    \n",
    "    @tf.function(jit_compile=True) \n",
    "    def model_mf3(input1, input2, input3, input4):\n",
    "        input1    = tf.reshape(input1, (1, 64))\n",
    "        input2    = tf.reshape(input2, (1, 25))\n",
    "        input3    = tf.reshape(input3, (1, 25))\n",
    "        input4    = tf.reshape(input4, (1, 25))\n",
    "        return models_3([input1,input2,input3,input4], training=False)[0]\n",
    "    \n",
    "    # def model_1(input):\n",
    "    #     coarse_data1 = tf.constant(solver_h4_data(input), dtype=tf.float32)\n",
    "    #     return model_mf1(input, coarse_data1).numpy().flatten()\n",
    "    @tf.function(jit_compile=True) \n",
    "    def model_cc(input):\n",
    "        inputx = tf.reshape(input, (1, 64))\n",
    "        return [Model(inputx, training=False)[0] for Model in model_nn]\n",
    "    \n",
    "    def model_1(input):\n",
    "        res = model_cc(input)\n",
    "        coarse_data1 = tf.constant(np.mean([tens.numpy() for tens in res],axis=0))\n",
    "        return model_mf1(input, coarse_data1).numpy().flatten()\n",
    "    \n",
    "    def model_2(input):\n",
    "        res = model_cc(input)\n",
    "        coarse_data1 = tf.constant(np.mean([tens.numpy() for tens in res],axis=0))\n",
    "        coarse_data2 = tf.constant(solver_h3_data(input), dtype=tf.float32)\n",
    "        return model_mf2(input, coarse_data2, coarse_data1).numpy().flatten()\n",
    "\n",
    "    def model_3(input):\n",
    "        coarse_data2 = tf.constant(solver_h3_data(input), dtype=tf.float32)\n",
    "        coarse_data3 = tf.constant(solver_h2_data(input), dtype=tf.float32)\n",
    "        res = model_cc(input)\n",
    "        coarse_data1 = tf.constant(np.mean([tens.numpy() for tens in res],axis=0))\n",
    "        return model_mf3(input, coarse_data3, coarse_data2,coarse_data1).numpy().flatten()\n",
    "    \n",
    "    def model_HF(input): return solver_h1_data(input).flatten()\n",
    "    \n",
    "    NUM_DATAPOINTS = 64\n",
    "    input_data = np.random.normal(size=(NUM_DATAPOINTS,1))\n",
    "    input1 =  input_data \n",
    "    input2 = solver_h4_data(input1)\n",
    "    input3 = solver_h3_data(input1)\n",
    "    input4 = solver_h2_data(input1)\n",
    "    execution_times = np.mean(repeat(lambda:  model_mf1(input1, input2,), number=1, repeat=500))\n",
    "    print(execution_times)\n",
    "\n",
    "elif case == \"1-step\":\n",
    "    # Load Models for Low- and Multi-fidelity Predictions\n",
    "    models_1 = load_model(f'models/multi_fidelity_100/input_10/samples_64000/model_fold_1.keras')\n",
    "    models_2 = load_model(f'models/multi_fidelity_100/input_10_25/samples_64000/model_fold_1.keras')\n",
    "    models_3 = load_model(f'models/multi_fidelity_100/input_10_25_50/samples_64000/model_fold_1.keras')\n",
    "\n",
    "    # # Define TensorFlow Functions with JIT Compilation\n",
    "    # @tf.function(jit_compile=True)\n",
    "    # def model_lf(input):\n",
    "    #     input_reshaped = tf.reshape(input, (1, 64))\n",
    "    #     return tf.reduce_mean([mod(input_reshaped, training=False)[0] for mod in models_l], axis=0)\n",
    "\n",
    "    @tf.function(jit_compile=True) \n",
    "    def model_mf1(input1, input2):\n",
    "        input1    = tf.reshape(input1, (1, 64))\n",
    "        input2    = tf.reshape(input2, (1, 25))\n",
    "        return models_1([input1,input2], training=False)[0]\n",
    "    \n",
    "    @tf.function(jit_compile=True) \n",
    "    def model_mf2(input1, input2, input3):\n",
    "        input1    = tf.reshape(input1, (1, 64))\n",
    "        input2    = tf.reshape(input2, (1, 25))\n",
    "        input3    = tf.reshape(input3, (1, 25))\n",
    "        return models_2([input1,input2,input3], training=False)[0]\n",
    "    \n",
    "    @tf.function(jit_compile=True) \n",
    "    def model_mf3(input1, input2, input3, input4):\n",
    "        input1    = tf.reshape(input1, (1, 64))\n",
    "        input2    = tf.reshape(input2, (1, 25))\n",
    "        input3    = tf.reshape(input3, (1, 25))\n",
    "        input4    = tf.reshape(input4, (1, 25))\n",
    "        return models_3([input1,input2,input3,input4], training=False)[0]\n",
    "    \n",
    "    # def model_1(input):\n",
    "    #     coarse_data1 = tf.constant(solver_h4_data(input), dtype=tf.float32)\n",
    "    #     return model_mf1(input, coarse_data1).numpy().flatten()\n",
    "    \n",
    "    def model_1(input):\n",
    "        coarse_data1 = tf.constant(solver_h4_data(input), dtype=tf.float32)\n",
    "        return model_mf1(input, coarse_data1).numpy().flatten()\n",
    "    \n",
    "    def model_2(input):\n",
    "        coarse_data1 = tf.constant(solver_h4_data(input), dtype=tf.float32)\n",
    "        coarse_data2 = tf.constant(solver_h3_data(input), dtype=tf.float32)\n",
    "        return model_mf2(input, coarse_data2, coarse_data1).numpy().flatten()\n",
    "\n",
    "    def model_3(input):\n",
    "        coarse_data1 = tf.constant(solver_h4_data(input), dtype=tf.float32)\n",
    "        coarse_data2 = tf.constant(solver_h3_data(input), dtype=tf.float32)\n",
    "        coarse_data3 = tf.constant(solver_h2_data(input), dtype=tf.float32)\n",
    "        return model_mf3(input, coarse_data3, coarse_data2,coarse_data1).numpy().flatten()\n",
    "    \n",
    "    def model_HF(input): return solver_h1_data(input).flatten()\n",
    "    \n",
    "    NUM_DATAPOINTS = 64\n",
    "    input_data = np.random.normal(size=(NUM_DATAPOINTS,1))\n",
    "    input1 =  input_data \n",
    "    input2 = solver_h4_data(input1)\n",
    "    input3 = solver_h3_data(input1)\n",
    "    input4 = solver_h2_data(input1)\n",
    "    execution_times = np.mean(repeat(lambda:  model_mf3(input1, input2, input3, input4), number=1, repeat=500))\n",
    "    print(execution_times)\n",
    "    execution_times = np.mean(repeat(lambda:  model_mf2(input1, input2, input3), number=1, repeat=500))\n",
    "    print(execution_times)\n",
    "    execution_times = np.mean(repeat(lambda:  model_mf1(input1, input2,), number=1, repeat=500))\n",
    "    print(execution_times)\n",
    "    \n",
    "elif case == \"MLDA\":\n",
    "    \n",
    "    model_1 = model_LF2\n",
    "    model_2 = model_LF1\n",
    "    model_3 = model_HF\n",
    "\n",
    "# Prior and Proposal Distributions\n",
    "x_distribution = stats.multivariate_normal(mean=np.zeros(64), cov=np.eye(64))\n",
    "Times, Time_ESS, ESS, samples_tot, ERR = [], [], [], [], []\n",
    "\n",
    "X_values = np.loadtxt('data/data/X_test_h1_100_01.csv', delimiter=',')\n",
    "y_values = np.loadtxt('data/data/y_test_h1_100_01.csv', delimiter=',')\n",
    "\n",
    "# Sampling for Each Random Sample\n",
    "for i, sample in enumerate(random_samples, start=1):\n",
    "    print(f'Sample = {sample}')\n",
    "    x_true = X_values[sample]\n",
    "    y_true = y_values[sample]\n",
    "    y_observed = y_true + np.random.normal(scale=noise, size=y_true.shape[0])\n",
    "\n",
    "    print(model_1(x_true))\n",
    "    print(y_true)\n",
    "    print(model_1(x_true).shape)\n",
    "    print(y_true.shape)\n",
    "    if case != \"FOM\":\n",
    "        print(f\"\\nMSE coarse simulation 1 test:  {np.sqrt(np.mean((model_1(x_true) - y_true)**2)):.4e}\")\n",
    "        print(f\"\\nMSE coarse simulation 2 test:  {np.sqrt(np.mean((model_2(x_true) - y_true)**2)):.4e}\")\n",
    "        print(f\"\\nMSE coarse simulation 3 test:  {np.sqrt(np.mean((model_3(x_true) - y_true)**2)):.4e}\")\n",
    "        print(f\"\\nMSE coarse simulation HF test:  {np.sqrt(np.mean((model_HF(x_true) - y_values[sample])**2)):.4e}\")\n",
    "        \n",
    "    \n",
    "    def ls(x):\n",
    "        return (y_true-model_HF(x))**2\n",
    "\n",
    "    res = least_squares(ls,np.zeros_like((x_true)), jac='3-point')\n",
    "    covariance = np.linalg.pinv(res.jac.T @ res.jac)\n",
    "    covariance *= 1/np.max(np.abs(covariance))\n",
    "    print(covariance[1:5,1:5])\n",
    "\n",
    "    # Likelihood Distributions\n",
    "    cov_likelihood = noise**2 * np.eye(25)\n",
    "    y_distribution_1 = tda.AdaptiveGaussianLogLike(y_observed, cov_likelihood*scaling1)\n",
    "    y_distribution_2 = tda.AdaptiveGaussianLogLike(y_observed, cov_likelihood*scaling2)\n",
    "    y_distribution_3 = tda.AdaptiveGaussianLogLike(y_observed, cov_likelihood*scaling3)\n",
    "    y_distribution_fine = tda.GaussianLogLike(y_observed, cov_likelihood)\n",
    "    my_proposal = tda.GaussianRandomWalk(C=covariance,scaling=1e-1, adaptive=True, gamma=1.1, period=10)\n",
    "    # Initialize Posteriors\n",
    "    my_posteriors = [\n",
    "        tda.Posterior(x_distribution, y_distribution_1, model_1), \n",
    "        tda.Posterior(x_distribution, y_distribution_2, model_2),\n",
    "        tda.Posterior(x_distribution, y_distribution_3, model_3)\n",
    "    ] if case != \"FOM\" else tda.Posterior(x_distribution, y_distribution_fine, model_HF)\n",
    "\n",
    "    # Run MCMC Sampling\n",
    "    start_time = timeit.default_timer()\n",
    "    samples = tda.sample(my_posteriors, my_proposal, iterations=n_iter, n_chains=1,\n",
    "                            initial_parameters=res.x, subchain_length=sub_sampling,\n",
    "                            adaptive_error_model='state-independent',store_coarse_chain=False)\n",
    "    elapsed_time = timeit.default_timer() - start_time\n",
    "\n",
    "    # Effective Sample Size (ESS)\n",
    "    idata = tda.to_inference_data(samples, level=2).sel(draw=slice(burnin, None, thin), groups=\"posterior\")\n",
    "    ess = az.ess(idata)\n",
    "    mean_ess = np.mean([ess.data_vars[f'x{j}'].values for j in range(64)])\n",
    "\n",
    "    # Store Results\n",
    "    Times.append(elapsed_time)\n",
    "    ESS.append(mean_ess)\n",
    "    Time_ESS.append(elapsed_time / mean_ess)\n",
    "    post = idata.posterior\n",
    "    val=post.mean().to_array()\n",
    "    err=(np.mean(np.sqrt((x_true-val)**2)))\n",
    "    ERR.append(err)\n",
    "    print(f'Time: {elapsed_time:.2f}, ESS: {mean_ess:.2f}, Time/ESS: {elapsed_time / mean_ess:.2f}, Err: {err:.3f} ({i}/{n_samples})')\n",
    "\n",
    "# Save Results\n",
    "output_folder = './data/recorded_values'\n",
    "np.save(os.path.join(output_folder, f'MDA_MF_{case}_ratio_001.npy'), Time_ESS)\n",
    "np.save(os.path.join(output_folder, f'MDA_MF_{case}_times_001.npy'), Times)\n",
    "np.save(os.path.join(output_folder, f'MDA_MF_{case}_err_001.npy'), ERR)\n",
    "np.save(os.path.join(output_folder, f'MDA_MF_{case}_ESS_001.npy'), ESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eccomas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
